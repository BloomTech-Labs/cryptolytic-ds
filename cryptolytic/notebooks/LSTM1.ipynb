{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/me/Documents/Git/Lambda-School-Labs/cryptolytic-ds\n",
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".MathJax {\n",
       "    font-size: 2rem;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ../..\n",
    "%run cryptolytic/notebooks/init.ipynb\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import cryptolytic.util as util\n",
    "import cryptolytic.start as start\n",
    "import cryptolytic.viz.plot as plot\n",
    "import cryptolytic.data.sql as sql\n",
    "import cryptolytic.data as d\n",
    "from cryptolytic.util import *\n",
    "import cryptolytic.data.historical as h\n",
    "import cryptolytic.model as m\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "from IPython.core.display import HTML\n",
    "from pandas.plotting import register_matplotlib_converters # to stop a warning message\n",
    "\n",
    "\n",
    "ohclv = ['open', 'high', 'close', 'low', 'volume']\n",
    "plt.style.use('ggplot')\n",
    "rcParams['figure.figsize'] = 20,7\n",
    "start.init()\n",
    "register_matplotlib_converters()\n",
    "\n",
    "\n",
    "# Make math readable\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax {\n",
    "    font-size: 2rem;\n",
    "}\n",
    "</style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    "\n",
    "### LSTM with Memory Between Batches\n",
    "\n",
    ">We can gain finer control over when the internal state of the LSTM network is cleared in Keras by making the LSTM layer “stateful”. This means that it can build state over the entire training sequence and even maintain that state if needed to make predictions.\n",
    "\n",
    ">It requires that the training data not be shuffled when fitting the network. It also requires explicit resetting of the network state after each exposure to the training data (epoch) by calls to model.reset_states(). This means that we must create our own outer loop of epochs and within each epoch call model.fit() and model.reset_states(). For example:\n",
    "\n",
    "```{python}\n",
    "for i in range(100):\n",
    "\tmodel.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "\tmodel.reset_states()\n",
    "```\n",
    "\n",
    ">Finally, when the LSTM layer is constructed, the stateful parameter must be set True and instead of specifying the input dimensions, we must hard code the number of samples in a batch, number of time steps in a sample and number of features in a time step by setting the batch_input_shape parameter. For example:\n",
    "```\n",
    "model.add(LSTM(4, batch_input_shape=(batch_size, time_steps, features), stateful=True))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/Documents/Git/Lambda-School-Labs/cryptolytic-ds/cryptolytic/data/__init__.py:54: FutureWarning:\n",
      "\n",
      "how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN_SPLIT = 5000\n",
    "history_size = 1000\n",
    "input_len = 8500\n",
    "train_size = int(5000*0.8)\n",
    "lahead = 10\n",
    "step = 2\n",
    "rolling_size = 6\n",
    "period = 300\n",
    "batch_size = 100\n",
    "to_drop = max(rolling_size - 1, lahead - 1)\n",
    "input_len = input_len + to_drop\n",
    "df = d.get_df ({'start':'06-01-2019', 'period':period, 'trading_pair':'eth_btc', 'exchange_id':'bitfinex'},\n",
    "               n=input_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>diff</th>\n",
       "      <th>arb_signal</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close_mean</th>\n",
       "      <th>volume_mean</th>\n",
       "      <th>diff_mean</th>\n",
       "      <th>arb_signal_mean</th>\n",
       "      <th>timestamp_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>close_skew</th>\n",
       "      <th>volume_skew</th>\n",
       "      <th>diff_skew</th>\n",
       "      <th>arb_signal_skew</th>\n",
       "      <th>timestamp_skew</th>\n",
       "      <th>close_kurt</th>\n",
       "      <th>volume_kurt</th>\n",
       "      <th>diff_kurt</th>\n",
       "      <th>arb_signal_kurt</th>\n",
       "      <th>timestamp_kurt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-06 06:00:00</th>\n",
       "      <td>0.039829</td>\n",
       "      <td>197.424839</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.047700</td>\n",
       "      <td>1546754400</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>127.217718</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>1.546755e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269907</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>-11031.203129</td>\n",
       "      <td>-0.417309</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>-1.893313</td>\n",
       "      <td>-0.417291</td>\n",
       "      <td>2.032476e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 06:05:00</th>\n",
       "      <td>0.039867</td>\n",
       "      <td>320.041091</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>-0.087709</td>\n",
       "      <td>1546754700</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>127.217718</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>1.546755e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269907</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>-11031.203129</td>\n",
       "      <td>-0.417309</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>-1.893313</td>\n",
       "      <td>-0.417291</td>\n",
       "      <td>2.032476e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 06:10:00</th>\n",
       "      <td>0.039870</td>\n",
       "      <td>70.079043</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.090318</td>\n",
       "      <td>1546755000</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>127.217718</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>1.546755e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269907</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>-11031.203129</td>\n",
       "      <td>-0.417309</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>-1.893313</td>\n",
       "      <td>-0.417291</td>\n",
       "      <td>2.032476e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 06:15:00</th>\n",
       "      <td>0.039840</td>\n",
       "      <td>18.358491</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.048922</td>\n",
       "      <td>1546755300</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>127.217718</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>1.546755e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269907</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>-11031.203129</td>\n",
       "      <td>-0.417309</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>-1.893313</td>\n",
       "      <td>-0.417291</td>\n",
       "      <td>2.032476e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-06 06:20:00</th>\n",
       "      <td>0.039804</td>\n",
       "      <td>9.974051</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.067172</td>\n",
       "      <td>1546755600</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>127.217718</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.059587</td>\n",
       "      <td>1.546755e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269907</td>\n",
       "      <td>0.780103</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>-11031.203129</td>\n",
       "      <td>-0.417309</td>\n",
       "      <td>-0.249835</td>\n",
       "      <td>-1.893313</td>\n",
       "      <td>-0.417291</td>\n",
       "      <td>2.032476e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        close      volume      diff  arb_signal   timestamp  \\\n",
       "datetime                                                                      \n",
       "2019-01-06 06:00:00  0.039829  197.424839  0.000001   -0.047700  1546754400   \n",
       "2019-01-06 06:05:00  0.039867  320.041091  0.000063   -0.087709  1546754700   \n",
       "2019-01-06 06:10:00  0.039870   70.079043  0.000001   -0.090318  1546755000   \n",
       "2019-01-06 06:15:00  0.039840   18.358491  0.000030   -0.048922  1546755300   \n",
       "2019-01-06 06:20:00  0.039804    9.974051  0.000037   -0.067172  1546755600   \n",
       "\n",
       "                     close_mean  volume_mean  diff_mean  arb_signal_mean  \\\n",
       "datetime                                                                   \n",
       "2019-01-06 06:00:00    0.039841   127.217718   0.000033        -0.059587   \n",
       "2019-01-06 06:05:00    0.039841   127.217718   0.000033        -0.059587   \n",
       "2019-01-06 06:10:00    0.039841   127.217718   0.000033        -0.059587   \n",
       "2019-01-06 06:15:00    0.039841   127.217718   0.000033        -0.059587   \n",
       "2019-01-06 06:20:00    0.039841   127.217718   0.000033        -0.059587   \n",
       "\n",
       "                     timestamp_mean  ...  close_skew  volume_skew  diff_skew  \\\n",
       "datetime                             ...                                       \n",
       "2019-01-06 06:00:00    1.546755e+09  ...   -0.269907     0.780103  -0.015923   \n",
       "2019-01-06 06:05:00    1.546755e+09  ...   -0.269907     0.780103  -0.015923   \n",
       "2019-01-06 06:10:00    1.546755e+09  ...   -0.269907     0.780103  -0.015923   \n",
       "2019-01-06 06:15:00    1.546755e+09  ...   -0.269907     0.780103  -0.015923   \n",
       "2019-01-06 06:20:00    1.546755e+09  ...   -0.269907     0.780103  -0.015923   \n",
       "\n",
       "                     arb_signal_skew  timestamp_skew  close_kurt  volume_kurt  \\\n",
       "datetime                                                                        \n",
       "2019-01-06 06:00:00         0.478313   -11031.203129   -0.417309    -0.249835   \n",
       "2019-01-06 06:05:00         0.478313   -11031.203129   -0.417309    -0.249835   \n",
       "2019-01-06 06:10:00         0.478313   -11031.203129   -0.417309    -0.249835   \n",
       "2019-01-06 06:15:00         0.478313   -11031.203129   -0.417309    -0.249835   \n",
       "2019-01-06 06:20:00         0.478313   -11031.203129   -0.417309    -0.249835   \n",
       "\n",
       "                     diff_kurt  arb_signal_kurt  timestamp_kurt  \n",
       "datetime                                                         \n",
       "2019-01-06 06:00:00  -1.893313        -0.417291    2.032476e+11  \n",
       "2019-01-06 06:05:00  -1.893313        -0.417291    2.032476e+11  \n",
       "2019-01-06 06:10:00  -1.893313        -0.417291    2.032476e+11  \n",
       "2019-01-06 06:15:00  -1.893313        -0.417291    2.032476e+11  \n",
       "2019-01-06 06:20:00  -1.893313        -0.417291    2.032476e+11  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = df[['close', 'volume', 'diff', 'arb_signal', 'timestamp']]\n",
    "a_df = c.rolling(rolling_size).mean().bfill().rename(columns=lambda x: x+'_mean')\n",
    "b_df = c.rolling(rolling_size).std().bfill().rename(columns=lambda x: x+'_std')\n",
    "c_df = c.rolling(rolling_size).skew().bfill().rename(columns=lambda x: x+'_skew')\n",
    "d_df = c.rolling(rolling_size).kurt().bfill().rename(columns=lambda x: x+'_kurt')\n",
    "df = pd.concat([c, a_df, b_df, c_df, d_df], axis=1).dropna(axis=1)\n",
    "# df_sub = df.drop(['timestamp', 'period', 'open', 'high', 'low', 'api', 'exchange', 'trading_pair'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    df = df.copy()\n",
    "    df = df._get_numeric_data()\n",
    "    # normalize each point by dividing by the inital point and subtracting 1\n",
    "    for col in df.columns: \n",
    "        df[col] = (df[col] / (df[col][0] + 1e-7)) - 1\n",
    "    return df\n",
    "    \n",
    "def denormalize(values, df, col=None):\n",
    "    values = values.copy()\n",
    "    if np.ndim(values) == 1:\n",
    "        return (1 + values) * df[col][0]\n",
    "    else:\n",
    "        for i in range(values.shape[1]):\n",
    "            if isinstance(values, pd.DataFrame): \n",
    "                values.iloc[:, i] = (1 + values.iloc[:, i]) * df.iloc[:, i][0]\n",
    "            else:\n",
    "                values[i] = (1 + values[:, i]) * df.iloc[:, i][0]\n",
    "        return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()\n",
    "# dataset = normalize_df(df._get_numeric_data()).values\n",
    "dataset = normalize(df._get_numeric_data())\n",
    "target = dataset.columns.get_loc('close') \n",
    "dataset = dataset.values\n",
    "y = dataset[:, target]\n",
    "\n",
    "# x_train, y_train = multivariate_data(dataset, y, 0, TRAIN_SPLIT, past_history, lahead, STEP, single_step=False)\n",
    "# x_val, y_val = multivariate_data(dataset, y,TRAIN_SPLIT, None, past_history,lahead, STEP,single_step=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed(df, target, batch_size, history_size, step, lahead=1, ratio=0.8):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    \n",
    "    x = dataset\n",
    "    y = dataset[:, target]\n",
    "\n",
    "    start = history_size # 1000\n",
    "    end = df.shape[0] - lahead # 4990\n",
    "    # 4990 - 1000 = 3990\n",
    "    for i in range(start, end):\n",
    "        # grab rows from i, to i+history_size\n",
    "        indices = range(i-history_size, i, step)\n",
    "        xs.append(x[indices])\n",
    "        ys.append(y[i:i+lahead])\n",
    "        \n",
    "    xs = np.array(xs)\n",
    "    ys = np.array(ys)\n",
    "    \n",
    "    nrows = xs.shape[0]\n",
    "    train_size = int(nrows * ratio)\n",
    "    # make sure the sizes are multiples of the batch size (needed for stateful lstm)\n",
    "    train_size -= train_size % batch_size\n",
    "    val_size = nrows - train_size\n",
    "    val_size -= val_size  % batch_size\n",
    "    total_size = train_size + val_size\n",
    "    xs = xs[:total_size]\n",
    "    ys = ys[:total_size]\n",
    "    \n",
    "    return xs[:train_size], ys[:train_size], xs[train_size:], ys[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5900, 500, 25), (5900, 10), (1500, 500, 25), (1500, 10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_val, y_val = windowed(dataset, target, batch_size, history_size, step, lahead)\n",
    "mapl(lambda x: x.shape, [x_train, y_train, x_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.08857092e-05,  2.00505330e-05,  7.21719965e-06, -5.44946701e-06,\n",
       "       -1.99528456e-05, -1.89525385e-05,  1.20579045e-05, -3.61306223e-06,\n",
       "        1.88958450e-05,  1.90649688e-05])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there is a slight error between the normlized values and the original values\n",
    "df.iloc[1000:1000+len(y_train[0])]['close_mean'].values - denormalize(y_train[0], df, 'close_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "#                      target_size, step, single_step=False):\n",
    "#    data = []\n",
    "#    labels = []\n",
    "#    \n",
    "#    start_index = start_index + history_size\n",
    "#    if end_index is None:\n",
    "#        end_index = len(dataset) - target_size\n",
    "#    \n",
    "#    for i in range(start_index, end_index):\n",
    "#        indices = range(i-history_size, i, step)\n",
    "#        data.append(dataset[indices])\n",
    "#        \n",
    "#        if single_step:\n",
    "#            labels.append(target[i+target_size])\n",
    "#        else:\n",
    "#            labels.append(target[i:i+target_size])\n",
    "#    \n",
    "#    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history : (500, 25)\n",
      "\n",
      " Target temperature to predict : (10,)\n"
     ]
    }
   ],
   "source": [
    "print ('Single window of past history : {}'.format(x_train[0].shape))\n",
    "print ('\\n Target temperature to predict : {}'.format(y_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single window of past history : (500, 25)\n",
      "\n",
      " Target temperature to predict : (10,)\n"
     ]
    }
   ],
   "source": [
    "print ('Single window of past history : {}'.format(x_train[0].shape))\n",
    "print ('\\n Target temperature to predict : {}'.format(y_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n",
      "/home/me/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning:\n",
      "\n",
      "Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BUFFER_SIZE = 10_000\n",
    "BATCH_SIZE = 250\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "def lstm_model(train, stateful):\n",
    "    model = tf.keras.models.Sequential()\n",
    "# use_bias is True\n",
    "    # batch size is 240 for the dataset instead of 256 for some reason\n",
    "    model.add(layers.LSTM(5, return_sequences=True, input_shape=(train.shape[-2:])))\n",
    "    model.add(layers.LSTM(5, activation='relu'))\n",
    "              \n",
    "    model.add(layers.Dense(lahead)) # global variable remove\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00005), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models\n",
    "def create_model(df, stateful):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.InputLayer(batch_size=batch_size, input_shape=x_train.shape[-2:]))\n",
    "    model.add(layers.Dense(128, use_bias=False))\n",
    "    model.add(layers.Dropout(0.05)) \n",
    "    model.add(layers.LayerNormalization())\n",
    "    model.add(layers.PReLU())\n",
    " #   model.add(layers.LSTM(64, \n",
    " #                  batch_size=batch_size,\n",
    " #                  input_shape=x_train.shape[-2:],\n",
    " #                  stateful=stateful,\n",
    " #                  return_sequences=True)\n",
    " #            )\n",
    "    model.add(layers.Dropout(0.05))\n",
    "    # Time Distributed\n",
    "    # Applies a layer to every temporal slice of an input. \n",
    "    # model.add(TimeDistributed(Dense(16)))\n",
    "    model.add(layers.LSTM(64, activation='relu', return_sequences=True))\n",
    "    model.add(layers.LSTM(64, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.LayerNormalization())\n",
    "    model.add(layers.Dropout(0.05))\n",
    "    model.add(layers.PReLU())\n",
    "    model.add(layers.Dense(126, activation='relu'))\n",
    "    model.add(layers.Dense(lahead))\n",
    "    #model.compile(loss='mse', optimizer='adam') \n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(df, stateful=True)\n",
    "history = {'loss':[],\n",
    "          'val_loss':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train on 5900 samples, validate on 1500 samples\n",
      "5900/5900 [==============================] - 71s 12ms/sample - loss: 0.0873 - val_loss: 0.0117\n",
      "Epoch 1\n",
      "Train on 5900 samples, validate on 1500 samples\n",
      "5900/5900 [==============================] - 68s 12ms/sample - loss: 0.1722 - val_loss: 0.0596\n",
      "Epoch 2\n",
      "Train on 5900 samples, validate on 1500 samples\n",
      "5900/5900 [==============================] - 67s 11ms/sample - loss: 0.0726 - val_loss: 0.0163\n",
      "Epoch 3\n",
      "Train on 5900 samples, validate on 1500 samples\n",
      "5900/5900 [==============================] - 68s 12ms/sample - loss: 0.1606 - val_loss: 0.0578\n",
      "Epoch 4\n",
      "Train on 5900 samples, validate on 1500 samples\n",
      "5900/5900 [==============================] - 66s 11ms/sample - loss: 0.1228 - val_loss: 0.0248\n"
     ]
    }
   ],
   "source": [
    "def run_model():\n",
    "    epochs = 10\n",
    "    for i in range(epochs):\n",
    "        print(f'Epoch {i}')\n",
    "        # batch size higher than 1 causes to fail, not sure\n",
    "        model.fit(x_train, y_train, \n",
    "                           batch_size=batch_size,\n",
    "                           epochs=1,\n",
    "                           verbose=1,\n",
    "                           use_multiprocessing=True,\n",
    "                           workers=4,\n",
    "                           validation_data = (x_val, y_val), \n",
    "                           shuffle=False)\n",
    "        history['loss'].append(model.history.history['loss'])\n",
    "        history['val_loss'].append(model.history.history['val_loss'])\n",
    "        model.reset_states()\n",
    "        \n",
    "    return model\n",
    "        \n",
    "model = run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = 10_000\n",
    "# BATCH_SIZE = 100\n",
    "# train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "# \n",
    "# val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "# val_data = val_data.batch(BATCH_SIZE).repeat()\n",
    "# \n",
    "# history = model.fit(train_data,\n",
    "#                 steps_per_epoch=38,\n",
    "#                 shuffle=False,     \n",
    "#                 epochs=1,\n",
    "#                 verbose=1,\n",
    "#                 use_multiprocessing=True,\n",
    "#                 workers=4,\n",
    "#                 validation_data=val_data,\n",
    "#                 validation_steps=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "    \n",
    "    plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
    "        label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "            label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_train_history(history, title):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    epochs = range(len(loss))\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_train_history(history, 'Multi Step Training and validation loss') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12277464928515887]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = denormalize(model.predict(x_train)[:, 0], df, 'close_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,3\n",
    "yo = 1000\n",
    "plt.plot(np.arange(yo), d.denoise(df['close'].iloc[history_size:yo+history_size], 5), label='actual')\n",
    "plt.plot(range(yo), d.denoise(preds[:yo], 5), label='predicted');\n",
    "plt.plot(range(yo), df.close_mean.values[history_size:yo+history_size], label='Mean')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('All predictions')\n",
    "# plt.plot(range(2000), d.denoise(preds[:2000], 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo = 1000\n",
    "val_actual = df['close_mean'].iloc[len(x_train):]\n",
    "val_preds = denormalize(model.predict(x_val)[:, 0], df, 'close_mean')\n",
    "plt.plot(np.arange(yo), d.denoise(val_actual, 5), label='actual')\n",
    "plt.plot(range(yo), d.denoise(preds[:yo], 5), label='predicted');\n",
    "# plt.plot(range(yo), df.close_mean.values[history_size:yo+history_size], label='Mean')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds = denormalize_results(model.predict(x_val))\n",
    "# # val_actual = df.close.iloc[TRAIN_SPLIT:]\n",
    "# val_actual = denormalize_results(y_val[:, 0])\n",
    "# plt.plot(np.arange(2000), d.denoise(val_actual[past_history:2000+past_history], 20), label='actual')\n",
    "# plt.plot(range(2000), d.denoise(val_preds[:, 0][:2000], 20), label='predicted');\n",
    "# plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
